{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a88ff0",
   "metadata": {},
   "source": [
    " Ejercicio: Manipulación de Datos\n",
    "\n",
    " Descripción del ejercicio:\n",
    "Desarrolle códigos para ejecutar las siguientes tareas:\n",
    "1. Cargue en la variable `df1` el conjunto de datos desde un archivo Excel.\n",
    "2. Cargue en la variable `df2` el conjunto de datos desde un archivo CSV.\n",
    "3. Cargue los datos Breast Cancer Wisconsin Dataset en un dataframe de pandas asignado a la variable `df3`.\n",
    "4. Construya un Panel con los tres (3) dataframes cargados anteriormente.\n",
    "5. Programe una función que extraiga todas las listas de los encabezados de columnas que se encuentran en un Panel.\n",
    "6. Programe una función que imprima la cantidad de elementos que tienen las bases de datos en un Panel.\n",
    "7. Filtre el dataframe `df1` para obtener las muestras de la empresa TAC y determine cuántos elementos tiene dicho filtro.\n",
    "8. Determine cuántos elementos nulos hay en cada una de las columnas del dataframe `df2`.\n",
    "\n",
    " Solución:\n",
    "\n",
    " Tareas 1 a 8: Implementar códigos para realizar cada tarea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a77da",
   "metadata": {},
   "source": [
    " Revisión Teórica: Estructuras de Datos y DataFrames\n",
    "\n",
    "En el contexto de la ciencia de datos y la programación, las estructuras de datos juegan un papel crucial en la manipulación y organización eficiente de los datos. Entre las estructuras de datos más utilizadas se encuentran las Series, los DataFrames y los Paneles. A continuación, se detallan las definiciones de cada una de estas estructuras:\n",
    "\n",
    " Series\n",
    "Una Serie es una estructura de datos unidimensional similar a un array en NumPy, pero con la capacidad adicional de tener etiquetas de índice asociadas a cada elemento. Esto significa que cada elemento de una Serie tiene una etiqueta de índice única que permite un acceso más intuitivo y eficiente a los datos. Las Series se utilizan comúnmente para representar una sola columna de datos en un conjunto de datos más grande.\n",
    "\n",
    "Por ejemplo, supongamos que tenemos una Serie que almacena la cantidad de ventas diarias de un producto durante una semana. La Serie podría tener una etiqueta de índice para cada día de la semana (por ejemplo, lunes, martes, miércoles, etc.) y el valor correspondiente sería la cantidad de ventas para ese día.\n",
    "\n",
    " DataFrame\n",
    "Un DataFrame es una estructura de datos bidimensional que se asemeja a una tabla de base de datos o una hoja de cálculo de Excel. Consiste en filas y columnas, donde cada columna puede contener diferentes tipos de datos. Los DataFrames son extremadamente versátiles y se utilizan ampliamente para almacenar y manipular datos tabulares.\n",
    "\n",
    "Por ejemplo, consideremos un DataFrame que almacena información sobre empleados en una empresa. Cada fila podría representar a un empleado individual, y cada columna podría contener información como el nombre, el salario, la edad, el departamento, etc.\n",
    "\n",
    "Panel\n",
    "Un Panel es una estructura de datos tridimensional que puede considerarse como un contenedor de múltiples DataFrames. Similar a un DataFrame, un Panel consta de filas y columnas, pero también tiene una dimensión adicional que representa diferentes aspectos o instancias del conjunto de datos. Aunque los Paneles son menos comunes que las Series y los DataFrames, pueden ser útiles en situaciones donde se necesite trabajar con múltiples conjuntos de datos bidimensionales.\n",
    "\n",
    "Por ejemplo, un Panel podría ser utilizado para almacenar datos de ventas de diferentes productos en diferentes regiones y períodos de tiempo. Cada DataFrame dentro del Panel representaría las ventas de un producto en una región específica durante un período de tiempo específico.\n",
    "\n",
    "Las definiciones y ejemplos proporcionados están basados en los siguientes recursos:\n",
    "\n",
    "- Galea, A. (2018). *Applied Data Science with Python and Jupyter: Use Powerful Industry-standard Tools to Unlock New, Actionable Insights From Your Data.* Packt Publishing. (pp. 22-28).\n",
    "- Boschetti, A., & Massaron, L. (2016). *Python Data Science Essentials - Second Edition.* Packt Publishing. (pp. 63-78).\n",
    "- Madhavan, S. (2015). *Mastering Python for Data Science: Explore the World of Data Science Through Python and Learn How to Make Sense of Data.* Packt Publishing. (pp. 7-18).\n",
    "- Vargas, M. (2022). *Carga de datos en Python desde un archivo Excel.* UNAD. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602e00b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            Unnamed: 1  \\\n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN   \n",
      "NaN                                                                NaN   \n",
      "NaN                                                            Empresa   \n",
      "Características                                                    TAB   \n",
      "Experiencia del conductor                           ≥ 30% Principiante   \n",
      "\n",
      "                                                            Unnamed: 2  \\\n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN   \n",
      "NaN                                                                NaN   \n",
      "NaN                                                                NaN   \n",
      "Características                                                    TAC   \n",
      "Experiencia del conductor                           ≥ 30% Principiante   \n",
      "\n",
      "                                                            Unnamed: 3  \\\n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN   \n",
      "NaN                                                                NaN   \n",
      "NaN                                                                NaN   \n",
      "Características                                                    TAD   \n",
      "Experiencia del conductor                           ≥ 40% Principiante   \n",
      "\n",
      "                                                            Unnamed: 4  \\\n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN   \n",
      "NaN                                                                NaN   \n",
      "NaN                                                                NaN   \n",
      "Características                                                    TAE   \n",
      "Experiencia del conductor                           ≥ 40% Principiante   \n",
      "\n",
      "                                                            Unnamed: 5  \n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN  \n",
      "NaN                                                                NaN  \n",
      "NaN                                                                NaN  \n",
      "Características                                                    TAP  \n",
      "Experiencia del conductor                           ≥ 40% Principiante  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path of the Excel file\n",
    "excel_path = r\"C:\\Users\\AIO\\Documents\\UNAD PRIMER SEMESTRE\\CURSOS\\PROGRAMACIÓN PARA EL ANÁLISIS DE DATOS\\Actividades\\Unidad 1\\actividad1\\Anexo 1 - Base de Datos EXCEL.xlsx\"\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df1 = pd.read_excel(excel_path, header=1, index_col=0)\n",
    "\n",
    "# Display the first few records of the DataFrame\n",
    "print(df1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f33e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  longitude,\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"\n",
      "0  -122.050000,37.370000,27.000000,3885.000000,66...                                                                                     \n",
      "1  -118.300000,34.260000,43.000000,1510.000000,31...                                                                                     \n",
      "2  -117.810000,33.780000,27.000000,3589.000000,50...                                                                                     \n",
      "3  -118.360000,33.820000,28.000000,67.000000,15.0...                                                                                     \n",
      "4  -119.670000,,19.000000,1241.000000,244.000000,...                                                                                     \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path of the CSV file\n",
    "csv_path = r\"C:\\Users\\AIO\\Documents\\UNAD PRIMER SEMESTRE\\CURSOS\\PROGRAMACIÓN PARA EL ANÁLISIS DE DATOS\\Actividades\\Unidad 1\\actividad1\\Anexo 2 - Base de Datos CSV.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df2 = pd.read_csv(csv_path, sep=';', header=0)\n",
    "\n",
    "# Display the first few records of the DataFrame\n",
    "print(df2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a5a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the Breast Cancer Wisconsin dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df3 = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Display the first few records of the DataFrame\n",
    "print(df3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ec1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario que contiene los DataFrames\n",
    "panel = {'df1': df1, 'df2': df2, 'df3': df3}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7187f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder al DataFrame df1\n",
    "df1_from_panel = panel['df1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bac3fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: df1\n",
      "                                                            Unnamed: 1  \\\n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN   \n",
      "NaN                                                                NaN   \n",
      "NaN                                                            Empresa   \n",
      "Características                                                    TAB   \n",
      "Experiencia del conductor                           ≥ 30% Principiante   \n",
      "\n",
      "                                                            Unnamed: 2  \\\n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN   \n",
      "NaN                                                                NaN   \n",
      "NaN                                                                NaN   \n",
      "Características                                                    TAC   \n",
      "Experiencia del conductor                           ≥ 30% Principiante   \n",
      "\n",
      "                                                            Unnamed: 3  \\\n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN   \n",
      "NaN                                                                NaN   \n",
      "NaN                                                                NaN   \n",
      "Características                                                    TAD   \n",
      "Experiencia del conductor                           ≥ 40% Principiante   \n",
      "\n",
      "                                                            Unnamed: 4  \\\n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN   \n",
      "NaN                                                                NaN   \n",
      "NaN                                                                NaN   \n",
      "Características                                                    TAE   \n",
      "Experiencia del conductor                           ≥ 40% Principiante   \n",
      "\n",
      "                                                            Unnamed: 5  \n",
      "Las atenciones de emergencias/urgencias médicas...                 NaN  \n",
      "NaN                                                                NaN  \n",
      "NaN                                                                NaN  \n",
      "Características                                                    TAP  \n",
      "Experiencia del conductor                           ≥ 40% Principiante  \n",
      "\n",
      "DataFrame: df2\n",
      "  longitude,\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"\n",
      "0  -122.050000,37.370000,27.000000,3885.000000,66...                                                                                     \n",
      "1  -118.300000,34.260000,43.000000,1510.000000,31...                                                                                     \n",
      "2  -117.810000,33.780000,27.000000,3589.000000,50...                                                                                     \n",
      "3  -118.360000,33.820000,28.000000,67.000000,15.0...                                                                                     \n",
      "4  -119.670000,,19.000000,1241.000000,244.000000,...                                                                                     \n",
      "\n",
      "DataFrame: df3\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre el diccionario y mostrar los primeros registros de cada DataFrame\n",
    "for df_name, df in panel.items():\n",
    "    print(f\"DataFrame: {df_name}\")\n",
    "    print(df.head())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193848c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: df1\n",
      "['Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5']\n",
      "\n",
      "DataFrame: df2\n",
      "['longitude,\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"']\n",
      "\n",
      "DataFrame: df3\n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_column_headers(panel):\n",
    "    \"\"\"\n",
    "    Extracts column headers from all DataFrames in a Panel.\n",
    "\n",
    "    Args:\n",
    "    - panel: Panel containing DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary where keys are DataFrame names and values are lists of column headers.\n",
    "    \"\"\"\n",
    "    column_headers = {}  # Dictionary to store column headers\n",
    "\n",
    "    # Iterate over DataFrames in the Panel\n",
    "    for df_name, df in panel.items():\n",
    "        # Extract column headers of the current DataFrame\n",
    "        column_headers[df_name] = df.columns.tolist()\n",
    "\n",
    "    return column_headers\n",
    "\n",
    "# Extract column headers from the panel\n",
    "column_headers = extract_column_headers(panel)\n",
    "\n",
    "# Print the results\n",
    "for df_name, headers in column_headers.items():\n",
    "    print(f\"DataFrame: {df_name}\")\n",
    "    print(headers)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c51deef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: df1, Number of elements: 145\n",
      "DataFrame: df2, Number of elements: 3000\n",
      "DataFrame: df3, Number of elements: 17070\n"
     ]
    }
   ],
   "source": [
    "def print_dataframe_sizes(panel):\n",
    "    \"\"\"\n",
    "    Prints the number of elements in each DataFrame in a Panel.\n",
    "\n",
    "    Args:\n",
    "    - panel: Panel containing DataFrames.\n",
    "    \"\"\"\n",
    "    # Iterate over DataFrames in the Panel\n",
    "    for df_name, df in panel.items():\n",
    "        # Get the number of elements in the current DataFrame\n",
    "        num_elements = df.size\n",
    "        # Print the DataFrame name and number of elements\n",
    "        print(f\"DataFrame: {df_name}, Number of elements: {num_elements}\")\n",
    "\n",
    "# Use the function with the panel from the previous point\n",
    "print_dataframe_sizes(panel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2da51ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de elementos para la empresa TAC: 1\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame df1 para obtener las muestras de la empresa TAC\n",
    "df1_tac = df1[df1['Unnamed: 2'] == 'TAC']\n",
    "\n",
    "# Determinar cuántos elementos tiene el filtro\n",
    "num_elements_tac = df1_tac.shape[0]\n",
    "\n",
    "# Imprimir la cantidad de elementos\n",
    "print(\"Número de elementos para la empresa TAC:\", num_elements_tac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "522cf964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de elementos nulos en cada columna del DataFrame df2:\n",
      "longitude,\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Contar la cantidad de elementos nulos en cada columna del DataFrame df2\n",
    "null_counts = df2.isnull().sum()\n",
    "\n",
    "# Imprimir la cantidad de elementos nulos en cada columna\n",
    "print(\"Cantidad de elementos nulos en cada columna del DataFrame df2:\")\n",
    "print(null_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10054cf",
   "metadata": {},
   "source": [
    "El ejercicio de manipulación de datos proporciona una visión completa de cómo cargar, manipular y analizar conjuntos de datos utilizando pandas en Python. \n",
    "\n",
    "- Carga de datos: Se cargaron tres conjuntos de datos diferentes desde archivos Excel, CSV y el conjunto de datos Breast Cancer Wisconsin, lo que demuestra la versatilidad de pandas para trabajar con diferentes formatos de datos.\n",
    "\n",
    "- Creación de un Panel: Se construyó un Panel que contiene los tres DataFrames cargados, lo que facilita la gestión y manipulación de múltiples conjuntos de datos en un solo objeto.\n",
    "\n",
    "- Extracción de encabezados de columnas: Se desarrolló una función para extraer los encabezados de columnas de todos los DataFrames en el Panel, lo que proporciona una visión general de la estructura de los datos en cada conjunto.\n",
    "\n",
    "- Impresión de la cantidad de elementos: Otra función se implementó para imprimir la cantidad de elementos en cada DataFrame del Panel, lo que ayuda a comprender el tamaño y la complejidad de los conjuntos de datos.\n",
    "\n",
    "- Filtrado de datos: Se filtraron muestras específicas en uno de los DataFrames (df1) para obtener solo las muestras relacionadas con la empresa TAC, lo que demuestra cómo realizar operaciones de filtrado para extraer información relevante.\n",
    "\n",
    "- Identificación de valores nulos: Se contaron los valores nulos en cada columna del DataFrame df2, lo que permite identificar y manejar los datos faltantes de manera adecuada.\n",
    "\n",
    "En resumen, este ejercicio ilustra las capacidades de pandas para cargar, manipular y analizar datos de manera eficiente, proporcionando herramientas poderosas para el análisis de datos en Python. Las funciones desarrolladas ofrecen una visión detallada de la estructura y el contenido de los conjuntos de datos, así como la capacidad de realizar operaciones de filtrado y limpieza de datos según sea necesario.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
